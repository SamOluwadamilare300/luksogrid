"use server"

import { revalidatePath } from "next/cache"

import { generatePrediction, fetchCoinMarketCapData } from "@/lib/ai"

export async function fetchAIPredictions(modelIds: number[] = [], limit = 10) {
  try {
    const predictions = await getAIPredictions(modelIds, limit)
    return { success: true, predictions }
  } catch (error) {
    console.error("Error fetching AI predictions:", error)
    return { success: false, error: "Failed to fetch predictions" }
  }
}

export async function createAIPrediction(modelId: number, asset: string, timeframe: string) {
  try {
    // Get the model details
    const model = await getAIModel(modelId)
    if (!model) {
      return { success: false, error: "Model not found" }
    }

    // Fetch market data from CoinMarketCap
    let marketData = null
    try {
      if (process.env.COINMARKETCAP_API_KEY) {
        marketData = await fetchCoinMarketCapData(asset, process.env.COINMARKETCAP_API_KEY)
      }
    } catch (error) {
      console.warn("Failed to fetch market data, continuing with prediction:", error)
    }

    // Generate prediction using DeepSeek
    const prediction = await generatePrediction(asset, timeframe, modelId, {
      marketData,
    })

    // Save prediction to database
    const savedPrediction = await saveAIPrediction(
      modelId,
      prediction.modelType,
      asset,
      prediction.confidence,
      prediction.action,
      prediction.reasoning,
      prediction.p0 || 0,   // Provide default if nullable
      prediction.model,      // Must provide
      timeframe,
      prediction.priceTarget,
    )

    revalidatePath("/app/ai-predictions")

    return { success: true, prediction: savedPrediction }
  } catch (error) {
    console.error("Error creating AI prediction:", error)
    return { success: false, error: "Failed to create prediction" }
  }
}

// Function to fetch historical predictions for performance analysis
export async function fetchHistoricalPredictions(asset: string, modelId?: number, limit = 30) {
  try {
    // Implementation would depend on your database schema
    // This is a placeholder for the actual implementation
    const predictions = await getAIPredictions(modelId ? [modelId] : [], limit)
    return { success: true, predictions }
  } catch (error) {
    console.error("Error fetching historical predictions:", error)
    return { success: false, error: "Failed to fetch historical predictions" }
  }
}
